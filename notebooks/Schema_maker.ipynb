{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Maker\n",
    "\n",
    "Creates a complete schema using an existing csv of sample or real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation file location and name\n",
    "common_dir = \"R:\\\\BERD Results System Development 2023\\\\DAP_emulation\\\\\"\n",
    "input_dir = \"outputs\\\\output_status_filtered_qa\"\n",
    "\n",
    "pref = \"status_filtered_qa\"\n",
    "suff = \"_2023-12-07_v245.csv\"\n",
    "\n",
    "# Output folder for all schemas\n",
    "out_dir = r\"D:\\programming_projects\\research-and-development\\config\\output_schemas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the top 100 rows, inferrring the schema from csv\n",
    "read_in_dir = common_dir + input_dir\n",
    "read_in_path = os.path.join(read_in_dir, pref + suff)\n",
    "df = pd.read_csv(read_in_path, nrows=100)\n",
    "\n",
    "\n",
    "# Remove \"index\" column if it exists\n",
    "if \"index\" in df.columns:\n",
    "    df = df.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: 236. Rows 100\n"
     ]
    }
   ],
   "source": [
    "shp = df.shape\n",
    "print(f\"columns: {shp[1]}. Rows {shp[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stringify the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names  as data types as dict of strings\n",
    "types = df.dtypes.to_dict()\n",
    "# Stringify the datatypes\n",
    "schema = {col[0]: str(col[1]) for col in types.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially, the schema is empty\n",
    "base_str = \"\"\n",
    "add_in_str = f'[{col}]\\nold_name = \"{col}\"\\nDeduced_Data_Type = \"{schema[col]}\"\\n\\n'\n",
    "\n",
    "\n",
    "# Iterate through columns, adding to the string which will be written to toml\n",
    "for col in schema:\n",
    "    base_str += add_in_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the schema toml file\n",
    "mypath = os.path.join(out_dir, pref + \"_schema.toml\")\n",
    "text_file = open(mypath, \"w\")\n",
    "text_file.write(S)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
